{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GNN_course6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMKb1xHwIq1hRU7Z6WmS9ta",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/almazav/Masters-Project/blob/main/GNN_course6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph Embedding methods 4\n",
        "## Graph Convolution Network GCN\n",
        "The GCN are a step forward from SGC and the formulation is given by:<br> \n",
        "$V^l = σ(\\tilde D^{-1/2}\\tilde A \\tilde D^{-1/2} V^{l-1} W^{l-1})$<br>\n",
        "where $V^l$ is the new representation of he features, $l$ is the layer, $W$is a project matrix(learnable paramater), when multiplied by the previous layer features $V^{l-i}$ it will project the features into a new space(linear) and reduce the dimension, $\\tilde D$ is the Degree matrix, used to normalize(needed to avoide exploding/vanishing gradients) the self conected adjecency matrix $\\tilde A$, ($\\tilde A = A +I$,adding a self loop to each node) and finally $σ$ is a non-linear fucntion such as ReLu.\n",
        "\n"
      ],
      "metadata": {
        "id": "G4PR1q2GHRBE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example \n",
        "Assume $N$ nodes with $M$ features, then:<br>\n",
        "$V$ is a $NxM$ matrix and $W$ is a $MxH$ matirx where $H$ is the hyper-paramters, then $VW$ is a $NxH$ matrix, and the mulpiplication $\\tilde D^{-1/2}\\tilde A\\tilde D^{-1/2}$ is a $NxN$, therefore the final resultig matrix is a $NxH$ matrix, an embedding matrix with $N$ nodes and $H$ dimension."
      ],
      "metadata": {
        "id": "L8_VRUWjKsFD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph Attention Network GAT\n",
        "Similarly to SGC is the equation of each feature node for each layer is given by:<br>\n",
        "$v_i^l = \\sigma(\\sum_{v_j\\in N(v_i)}\\alpha_{ij}v_j^{l-1}W^{l-1})$<br>\n",
        "where $W$ is the usual linear learanble projection matrix, $\\alpha_{ij}$ is a weighted average of feature nodes and the neighbour nodes, and $\\sigma$ is a non-linear function such as sigmoid or ReLu. Therefore the main difference between GCN and GAT is $\\alpha_{ij}$, which we construct via a function $\\alpha_{ij} = f(v_i,v_j,W)$.<br> #~In order to obtain this function we need:\n",
        "* Multiply the 2 neighbour nodes by $W$\n",
        "* Concatenate features togheter\n",
        "* Dot product with of concatenated features with weight vector\n",
        "* pass it into a LeakyReLu to get scalar value\n",
        "* Apply softmax "
      ],
      "metadata": {
        "id": "-IVZjc0qVbnu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\rho_{i,j} = LeakyReLu(a^T[v_i^{(l-1)}W^{l-1}||v_j^{(l-1)}W^{l-1}])$<br>\n",
        "In this case we have a second learnable paramtere $a$ the weight vector"
      ],
      "metadata": {
        "id": "tL3j9jZhVmOB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\alpha_{i,j} = exp(\\rho_{i,j})/\\sum_{j \\in N(i)} exp(\\rho_{i,j})$"
      ],
      "metadata": {
        "id": "woUNdjbraHod"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is possible to introuduce multiple learnable parameters $W$ and $\\alpha$ this is known as Multi-head attention Neural Network. "
      ],
      "metadata": {
        "id": "1PGzQvGtarF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "u-jWftNFbhD0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}